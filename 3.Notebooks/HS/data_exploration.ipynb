{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMTBxzuAlhmIgYZ/b6I0qdO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V7g7FHwTL-27","executionInfo":{"status":"ok","timestamp":1690678349100,"user_tz":420,"elapsed":1095,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}},"outputId":"9dffa09f-9a4a-4e16-d973-5bef46a518fb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive, auth\n","import sys\n","import numpy as np\n","import pandas as pd\n","import tensorflow_hub as hub\n","import librosa\n","import matplotlib.pyplot as plt\n","import csv\n","from IPython.display import Audio\n","\n","#sklearn libraries\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","\n","#tensorflow for modles\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Dropout, LSTM, Conv2D, MaxPooling2D, Flatten, concatenate, Reshape, BatchNormalization\n","import tensorflow_hub as hub\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras import regularizers\n","from tensorflow.keras.callbacks import Callback,EarlyStopping\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow import keras\n","from keras import metrics\n","tf.get_logger().setLevel('INFO')\n","\n","#mount drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["#declare sampling rate\n","sampling_rate = 16000\n","#get the audio path of all the audios\n","audio_path = '/content/drive/MyDrive/UCB-MIDS/SEM-2/MACHINE-LEARNING-207/207-Project/data/train/librosa_loaded/'"],"metadata":{"id":"nCjkPymzSKoD","executionInfo":{"status":"ok","timestamp":1690678374336,"user_tz":420,"elapsed":169,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["#Read the data and get the shapes of the dataframe\n","bird_df = pd.read_csv('/content/drive/MyDrive/UCB-MIDS/SEM-2/MACHINE-LEARNING-207/207-Project/notebooks/RG/3_species/train_val.csv')\n","bird_df.shape\n","\n","#Gather the training data from the main dataset\n","bird_train_df = bird_df[bird_df['data'] == 'train']\n","print(\"train data:\",bird_train_df.shape)\n","\n","#Gather the separate validation set from the csv\n","bird_val_df =  bird_df[bird_df['data'] == 'val']\n","print(\"validation data:\",bird_val_df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZRXx4Xq-SLOd","executionInfo":{"status":"ok","timestamp":1690678384195,"user_tz":420,"elapsed":3057,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}},"outputId":"6f620fb7-3eb2-4ae7-fe46-f837c5413959"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["train data: (657, 9)\n","validation data: (283, 9)\n"]}]},{"cell_type":"code","source":["#Function to load the audio\n","def load_audio(file_name):\n","    audio = np.load(audio_path + file_name)\n","    return audio"],"metadata":{"id":"eKKHiJM4SOTc","executionInfo":{"status":"ok","timestamp":1690678389232,"user_tz":420,"elapsed":167,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["#chunk the audio into 5 sec frame with no overlaps\n","def frame_audio(\n","      audio_array: np.ndarray,\n","      window_size_s: float = 8.0,\n","      hop_size_s: float = 4.0,\n","      sample_rate = sampling_rate,\n","      ) -> np.ndarray:\n","\n","    \"\"\"Helper function for framing audio for inference.\"\"\"\n","    \"\"\" using tf.signal \"\"\"\n","    if window_size_s is None or window_size_s < 0:\n","        return audio_array[np.newaxis, :]\n","    frame_length = int(window_size_s * sample_rate)\n","    hop_length = int(hop_size_s * sample_rate)\n","    framed_audio = tf.signal.frame(audio_array, frame_length, hop_length, pad_end=False)\n","    return framed_audio"],"metadata":{"id":"AaRwgnX4SP79","executionInfo":{"status":"ok","timestamp":1690678396274,"user_tz":420,"elapsed":142,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["#extract mfcc from frames\n","def extract_mfcc_from_frames(framed_audio, class_label, sample_rate=16000, n_mfcc=40):\n","  mfcc_frames = []\n","  target_label = []\n","  for frame in framed_audio:\n","    frame = np.array(frame)\n","\n","    #Extract mfcc from the main audio frame\n","    mfcc = librosa.feature.mfcc(y=frame, sr=sample_rate, n_mfcc=n_mfcc)\n","\n","    #Transpose the MFCC matrix\n","    transposed_mfcc = mfcc.T\n","\n","    #lets get the mfcc\n","    mfcc_frames.append(transposed_mfcc)\n","\n","    #append the labels for every frame\n","    target_label.append(class_label)\n","\n","  return mfcc_frames,target_label"],"metadata":{"id":"cWbT6yQWSQpT","executionInfo":{"status":"ok","timestamp":1690678663784,"user_tz":420,"elapsed":263,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import librosa\n","import numpy as np\n","from IPython.display import Audio\n","\n","def split_audio_and_time_stretch(audio_file, duration, sampling_rate, target_duration):\n","    # Load the audio using librosa\n","    audio, _ = librosa.load(audio_file, sr=sampling_rate)\n","\n","    # Calculate the time stretch factor to make the audio segments target_duration seconds long\n","    time_stretch_factor = target_duration / duration\n","\n","    # Resample the audio to make it target_duration seconds long\n","    audio_stretched = librosa.resample(audio, orig_sr=sampling_rate, target_sr=int(sampling_rate * time_stretch_factor))\n","\n","    # Split the audio into segments of target_duration seconds\n","    num_segments = len(audio_stretched) // (target_duration * sampling_rate)\n","    time_stretched_segments = np.array_split(audio_stretched, num_segments)\n","\n","    return time_stretched_segments"],"metadata":{"id":"6iQZxEyqSUo9","executionInfo":{"status":"ok","timestamp":1690679535328,"user_tz":420,"elapsed":152,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["audio_file = \"/content/drive/MyDrive/UCB-MIDS/SEM-2/MACHINE-LEARNING-207/207-Project/BirdCLEF/train_audio/abethr1/XC128013.ogg\"  # Replace with the path to your audio file\n","duration = 46  # Replace with the duration of the original audio in seconds\n","sampling_rate = 22050  # Replace with the sampling rate of your audio file\n","target_duration = 8  # Replace with the desired duration of each segment in seconds\n","\n","# Call the function\n","time_stretched_segments = split_audio_and_time_stretch(audio_file, duration, sampling_rate, target_duration)\n","\n","# Listen to each time-stretched segment\n","for i, segment in enumerate(time_stretched_segments):\n","    display(Audio(segment, rate=sampling_rate))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":381},"id":"-77kHUNmT0KG","executionInfo":{"status":"error","timestamp":1690679572393,"user_tz":420,"elapsed":422,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}},"outputId":"bad6522a-c49c-4525-a43b-b038677916bb"},"execution_count":20,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-2f11d7dfb2f1>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Call the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mtime_stretched_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_audio_and_time_stretch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_duration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Listen to each time-stretched segment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-18-2e334e33f8f4>\u001b[0m in \u001b[0;36msplit_audio_and_time_stretch\u001b[0;34m(audio_file, duration, sampling_rate, target_duration)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;31m# Split the audio into segments of target_duration seconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mnum_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_stretched\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget_duration\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msampling_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtime_stretched_segments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_stretched\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_segments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtime_stretched_segments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36marray_split\u001b[0;34m(*args, **kwargs)\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36marray_split\u001b[0;34m(ary, indices_or_sections, axis)\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mNsections\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_or_sections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mNsections\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 778\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'number sections must be larger than 0.'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    779\u001b[0m         \u001b[0mNeach_section\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextras\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdivmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNtotal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNsections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         section_sizes = ([0] +\n","\u001b[0;31mValueError\u001b[0m: number sections must be larger than 0."]}]},{"cell_type":"code","source":["#Count the number of audio files that are exactly 15 seconds\n","num_15_sec = len(bird_train_df[bird_train_df['duration_secs_32000'] > 8])\n","\n","#Count the number of audio files that are less than 15 seconds\n","num_less_than_15_sec = len(bird_train_df[bird_train_df['duration_secs_32000'] < 8])\n","\n","print(\"Number of audio files that are exactly 8 seconds:\", num_15_sec)\n","print(\"Number of audio files that are less than 8 seconds:\", num_less_than_15_sec)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j14cq7lMWWrP","executionInfo":{"status":"ok","timestamp":1690679617805,"user_tz":420,"elapsed":158,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}},"outputId":"16b3bd0e-4ccf-4f1d-e241-077752d36217"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of audio files that are exactly 8 seconds: 560\n","Number of audio files that are less than 8 seconds: 97\n"]}]},{"cell_type":"code","source":["# Assuming bird_train_df is your DataFrame containing the audio information\n","# Find audio files with duration less than 6 seconds\n","audios_less_than_6_sec = bird_train_df[bird_train_df['duration_secs_32000'] < 6]\n","\n","# Group the DataFrame by primary_label and get the count of audio files in each group\n","grouped_by_primary_label = audios_less_than_6_sec.groupby('primary_label').size()\n","\n","# Display the count of audio files for each primary_label\n","print(grouped_by_primary_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SShXhhLXW_kk","executionInfo":{"status":"ok","timestamp":1690679929615,"user_tz":420,"elapsed":147,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}},"outputId":"ba79f3b4-547a-4ac3-aa1c-a98368331773"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["primary_label\n","barswa      7\n","comsan     19\n","eaywag1     8\n","dtype: int64\n"]}]},{"cell_type":"code","source":["# Assuming bird_train_df is your DataFrame containing the audio information\n","# Find audio files with duration less than 6 seconds\n","audios_less_than_6_sec = bird_train_df[bird_train_df['duration_secs_32000'] < 10]\n","\n","# Group the DataFrame by primary_label and get the count of audio files in each group\n","grouped_by_primary_label = audios_less_than_6_sec.groupby('primary_label').size()\n","\n","# Display the count of audio files for each primary_label\n","print(grouped_by_primary_label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tZ6wLf4eZPCV","executionInfo":{"status":"ok","timestamp":1690681329673,"user_tz":420,"elapsed":310,"user":{"displayName":"Hamsini Sankaran","userId":"08639212824741438185"}},"outputId":"b085bc9b-d9c6-49b9-a4e2-7831441451a3"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["primary_label\n","barswa     30\n","comsan     73\n","eaywag1    41\n","dtype: int64\n"]}]}]}